{
  "name": "inception-onnx",
  "version": "2.0.0",
  "description": "Multi-platform ONNX inference service with ARM64 CPU and CUDA GPU acceleration",
  "type": "module",
  "scripts": {
    "dev": "bun run --watch src/index.ts",
    "start": "bun run src/index.ts",
    "cli": "bun run src/cli.ts",
    "build": "bun build src/index.ts --outdir dist --target bun",
    "test": "bun test",
    "test:integration": "bun test --timeout 60000 test/*.integration.test.ts",
    "test:benchmark": "bun test test/benchmark.test.ts",
    "typecheck": "tsc --noEmit",
    "lint": "eslint src/**/*.ts",
    "check-models": "bun run src/cli.ts --check",
    "benchmark": "bun run src/cli.ts --benchmark"
  },
  "dependencies": {
    "hono": "^4.6.0",
    "@hono/node-server": "^1.13.0",
    "onnxruntime-node": "^1.20.0",
    "@xenova/transformers": "^2.17.0",
    "axios": "^1.7.0",
    "chalk": "^5.3.0",
    "commander": "^12.1.0",
    "dotenv": "^16.4.0",
    "prom-client": "^15.1.0",
    "sharp": "^0.33.0"
  },
  "devDependencies": {
    "@types/bun": "latest",
    "@types/node": "^22.0.0",
    "typescript": "^5.6.0",
    "eslint": "^9.0.0",
    "@typescript-eslint/eslint-plugin": "^8.0.0",
    "@typescript-eslint/parser": "^8.0.0"
  },
  "engines": {
    "bun": ">=1.0.0"
  },
  "author": "",
  "license": "MIT"
}
